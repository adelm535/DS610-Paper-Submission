{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaHYZyCtdKHn",
        "outputId": "91259dd3-2aaf-40bb-ccf2-86c7104093b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.4 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.1.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.29.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.51.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (23.1.4)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UxiWlcviceZK"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU,SimpleRNN\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D, Input\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IK2FCSfTceZN"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('Corona_NLP_train.csv', encoding = 'latin1') \n",
        "test = pd.read_csv('Corona_NLP_test.csv', encoding = 'latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "svW-ZLzFceZO",
        "outputId": "45f2f392-fc78-45cd-8513-fdbe0ef02d6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1  advice Talk to your neighbours family to excha...            Positive  \n",
              "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3  My food stock is not the only one which is emp...            Positive  \n",
              "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf00fd55-0710-478b-93af-8775d822e376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf00fd55-0710-478b-93af-8775d822e376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf00fd55-0710-478b-93af-8775d822e376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf00fd55-0710-478b-93af-8775d822e376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LcPAR2wceZO",
        "outputId": "0cde03d5-1b0e-4db8-86e7-db9964c985a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41157, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtptOX2rceZP",
        "outputId": "8abd774c-1ba8-46f0-f91c-7631a0c47502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
              "       'Extremely Positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "label = train['Sentiment'].unique()\n",
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Vd5gtNCGceZP",
        "outputId": "54f81606-244c-4257-d19d-1fefb34417f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5ec236310>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc={'figure.figsize':(11,4)})\n",
        "sns.countplot(train['Sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWdQqbbeceZQ"
      },
      "source": [
        "**Remove Stop words from train and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru59y8t_ceZR",
        "outputId": "42f86acd-f367-4eab-f8e7-b7176c2c19ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-k8Q_lceZS",
        "outputId": "0f9950b0-3589-452d-dc04-0039bc038094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [T, R, E, N, D, I, N, G, :,  , N, e, w,  , Y, ...\n",
              "1       [W, h, e, n,  , I,  , c, u, l, n, ',  , f, n, ...\n",
              "2       [F, n,  , u,  , h, w,  , u,  , c, n,  , p, r, ...\n",
              "3       [#, P, n, c,  , b, u, n, g,  , h,  , #, N, e, ...\n",
              "4       [#, l, e, p, p, e, r,  , #, u, n, n, p, p, e, ...\n",
              "                              ...                        \n",
              "3793    [M, e, n, w, h, l, e,  , I, n,  , A,  , S, u, ...\n",
              "3794    [D,  , u,  , p, n, c,  , b, u,  ,  , l,  , f, ...\n",
              "3795    [A,  , P, r, f,  , f,  , E, c, n, c,  , @, c, ...\n",
              "3796    [G, v,  , n, e, e,  ,  ,  , e, h, n, g,  , n, ...\n",
              "3797    [I,  , n,  , @, F, r, e, n, P, p, e, r,  , e, ...\n",
              "Name: OriginalTweet, Length: 3798, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train['OriginalTweet'].apply(lambda x: [item for item in x if item not in stop])\n",
        "test['OriginalTweet'].apply(lambda x: [item for item in x if item not in stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGZT38_TceZT"
      },
      "source": [
        "# Convert categorical variable into dummy/indicator variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLoUbPuYceZU",
        "outputId": "2e61ecd0-b744-491b-f996-aa0b97a2a80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label :        Extremely Negative  Extremely Positive  Negative  Neutral  Positive\n",
            "0                       0                   0         0        1         0\n",
            "1                       0                   0         0        0         1\n",
            "2                       0                   0         0        0         1\n",
            "3                       0                   0         0        0         1\n",
            "4                       1                   0         0        0         0\n",
            "...                   ...                 ...       ...      ...       ...\n",
            "41152                   0                   0         0        1         0\n",
            "41153                   1                   0         0        0         0\n",
            "41154                   0                   0         0        0         1\n",
            "41155                   0                   0         0        1         0\n",
            "41156                   0                   0         1        0         0\n",
            "\n",
            "[41157 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "y=train['Sentiment'].values\n",
        "y = pd.get_dummies(y)\n",
        "print('Shape of label :', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIikoHcvceZV"
      },
      "source": [
        "# Tokenization\n",
        "Tokenization is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords. Hence, tokenization can be broadly classified into 3 types – word, character, and subword (n-gram characters) tokenization.\n",
        "\n",
        "Here, we use keras.processing class Tokenizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWqOJqZbceZf"
      },
      "source": [
        "# Encoding Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsrYEz7dceZf"
      },
      "source": [
        "We would tokenize our entire data, so I'd create a new dataframe combining the tweet values of both train and test data, and fit our tokenizer on this new dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jckzc8ysceZg"
      },
      "source": [
        "Now, having initalized a tokenizer in the previous step, we would now use the tokenizer to convert the text from train dataset to tokens, and pad the values with 0s to ensure a uniform length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgKgOZUwceZg",
        "outputId": "58ac6dea-1c33-411b-fb9d-2eaef2e1693c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24677"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tmp = train['OriginalTweet'] + test['OriginalTweet']\n",
        "tmp = tmp.astype(str)\n",
        "tokenizer = text.Tokenizer(num_words=400000,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True,\n",
        "    split=\" \")\n",
        "max_len = 70\n",
        "tokenizer.fit_on_texts(tmp)\n",
        "word_index = tokenizer.word_index\n",
        "len(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TkeZeMRceZg",
        "outputId": "7f004972-ac6d-4595-edc5-2e9114725254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (41157, 70)\n"
          ]
        }
      ],
      "source": [
        "X = train['OriginalTweet'].values\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X = keras.preprocessing.sequence.pad_sequences(X, maxlen=max_len)\n",
        "print('Shape of data tensor:', X.shape)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcRRvl9nceZh"
      },
      "source": [
        "# Splitting the data\n",
        "We would split up our train dataset into xtrain, xvalid, ytrain and yvalid. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ijlWwcdyceZh"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                  random_state=46, \n",
        "                                                  test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG-YccFQceZh",
        "outputId": "906511da-95a8-446b-e025-48de1f8e5963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (28809, 70)  y_train.shape: (28809, 5)\n",
            "x_test.shape: (12348, 70)  y_train.shape: (12348, 5)\n"
          ]
        }
      ],
      "source": [
        "print('x_train.shape: ' + str(x_train.shape),' y_train.shape: '+str(y_train.shape))\n",
        "print('x_test.shape: ' + str(x_test.shape),' y_train.shape: '+str(y_test.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Kk3dZ1ceZh"
      },
      "source": [
        "# The Embedding Layer\n",
        "\n",
        "\n",
        "> Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, and hence the technique is often lumped into the field of deep learning.\n",
        "\n",
        "\n",
        "\n",
        "using pre trained Glove vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yvVHAmkt9ls",
        "outputId": "6cf1b9a6-faaf-4e71-f5e6-6ec84cb5a7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-09 20:41:51--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2023-01-09 20:41:52--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2023-01-09 20:41:52--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.02MB/s    in 6m 51s  \n",
            "\n",
            "2023-01-09 20:48:44 (5.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ykmzUHnTt-pZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2609dcf-9642-42a3-d71f-1dd761232404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ]
        }
      ],
      "source": [
        "!unzip glove.840B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m8ojgn3nceZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096991ba-2c47-4369-b311-64e1277ff35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2196017it [02:52, 12733.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2196016 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.840B.300d.txt','r',encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray([float(val) for val in values[1:]])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c1bVzdecceZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710cd435-fd6b-464f-c559-0e53ff4f15ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24677/24677 [00:00<00:00, 390814.19it/s]\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zesc-P3jceZi"
      },
      "source": [
        "# Model Building\n",
        "\n",
        "This is the part where it gets interesting. After all the process of cleaning, tokenizing, embedding words, we're now ready to create our model and feed the data into it and check which model gives a better accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRbPj-jPceZj"
      },
      "source": [
        "**1. Simple RNN (Recurrent Neural Networks) Model**\n",
        "\n",
        "We'll start off with a very simple RNN model. If you're new to the concept of tensorflow, have a [quick look](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
        "\n",
        "Let's first address the question. \n",
        "\n",
        "What is RNN?\n",
        "\n",
        "Recurrent neural networks (RNN) are a class of neural networks that are helpful in modeling sequence data. Derived from feedforward networks, RNNs exhibit similar behavior to how human brains function. Simply put: recurrent neural networks produce predictive results in sequential data that other algorithms can’t.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SkGlNKRceZj"
      },
      "outputs": [],
      "source": [
        "SimpleRNNModel = Sequential()\n",
        "SimpleRNNModel.add(Input(shape=x_train.shape[1]))\n",
        "SimpleRNNModel.add(Embedding(len(tokenizer.word_index)+1,32))\n",
        "SimpleRNNModel.add(SimpleRNN(100))\n",
        "SimpleRNNModel.add(Dense(5, activation='softmax'))\n",
        "#SimpleRNNModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "SimpleRNNModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
        "SimpleRNNModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5neYoTnceZj"
      },
      "source": [
        "# Fitting the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVr8AlQoceZj"
      },
      "outputs": [],
      "source": [
        "\n",
        "SimpleRNNModelResults = SimpleRNNModel.fit(x_train, y_train, epochs=5, batch_size=64,validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulSMxG2mceZk"
      },
      "source": [
        "# Overfitting Model Alert!\n",
        "So, I see the accuracy is quite high ~95%, and also high precision, recall and AUC but the val_accuracy is not that great. This means that there might be a possibility of overfitting, where in the model performs well with the train data, but while performing with new data which it isn't trained with, it might not be performing quite well. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Xb8CgzceZk"
      },
      "source": [
        "**Preprocessing the test dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJbxcVBSceZk"
      },
      "source": [
        "**2. LSTM (Long Short Term Memory) Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0zIvEZAceZk"
      },
      "source": [
        "> Long short-term memory is an artificial recurrent neural network architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points, but also entire sequences of data.\n",
        "\n",
        "Technically, LSTM was built to overcome the [vanishing gradient](https://medium.datadriveninvestor.com/how-do-lstm-networks-solve-the-problem-of-vanishing-gradients-a6784971a577) issue encountered in RNNs. In simple words, RNN training is something like this. From each layer, the error is backpropagated to update the weights of previous layers, but in a case where the gradient is exponentially so less, that it becomes insignificant and the weights are not updated at all. We call this as the *vanishing gradient* problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzEl2RNGceZk"
      },
      "source": [
        "I'd first try with a simple LSTM model, with a very similar architecture as of the simple RNN model and check how much accuracy that gives us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaP7SV1-ceZl"
      },
      "outputs": [],
      "source": [
        "SimpleLSTMModel = Sequential()\n",
        "SimpleLSTMModel.add(Input(shape=x_train.shape[1]))\n",
        "SimpleLSTMModel.add(Embedding(len(tokenizer.word_index)+1,32))\n",
        "SimpleLSTMModel.add(LSTM(100))\n",
        "SimpleLSTMModel.add(Dense(5, activation='softmax'))\n",
        "SimpleLSTMModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "SimpleLSTMModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvSy2QUFceZl"
      },
      "outputs": [],
      "source": [
        "\n",
        "SimpleLSTMModelResults = SimpleLSTMModel.fit(x_train, y_train, epochs=5, batch_size=64,validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrvZc3gceZl"
      },
      "source": [
        "the improvement is noticable changing the model from Simple RNN to LSTM and no overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc99lWahceZl"
      },
      "source": [
        "**3. GRU Gated Recurrent Units**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3IrjN2zceZm"
      },
      "source": [
        "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47oOHATxceZm"
      },
      "outputs": [],
      "source": [
        "SimpleGRUModel = Sequential()\n",
        "SimpleGRUModel.add(Input(shape=x_train.shape[1]))\n",
        "SimpleGRUModel.add(Embedding(len(tokenizer.word_index)+1,32))\n",
        "SimpleGRUModel.add(GRU(100))\n",
        "SimpleGRUModel.add(Dense(5, activation='softmax'))\n",
        "SimpleGRUModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "SimpleGRUModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhToObAtceZm"
      },
      "outputs": [],
      "source": [
        "\n",
        "SimpleGRUModelResults = SimpleGRUModel.fit(x_train, y_train, epochs=5, batch_size=64,validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROuF2cBdceZn"
      },
      "source": [
        "**4. Bidirectional LSTM Model**\n",
        "\n",
        "The Bidirectional LSTM or BiLSTM is a modified version of a simple LSTM, where we use 2 LSTM models, one processing the input and learning occuring in a forward direction and one for backward. It is proven better in terms of accuracy than traditional RNN/GRU and LSTM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flOT0MVfceZn"
      },
      "outputs": [],
      "source": [
        "BILSTMModel_2 = Sequential()\n",
        "BILSTMModel_2.add(Input(shape=x_train.shape[1]))\n",
        "BILSTMModel_2.add(Embedding(24678,300, weights=[embedding_matrix]))\n",
        "BILSTMModel_2.add(Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
        "BILSTMModel_2.add(GlobalMaxPooling1D())\n",
        "BILSTMModel_2.add(Dense(50, activation='relu'))\n",
        "BILSTMModel_2.add(Dropout(0.2))\n",
        "BILSTMModel_2.add(Dense(5, activation='softmax'))\n",
        "BILSTMModel_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "BILSTMModel_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kqn50ye3ceZn",
        "outputId": "65463d73-aca6-4157-8a48-a8ceac873b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "406/406 [==============================] - 260s 620ms/step - loss: 1.1338 - accuracy: 0.5246 - val_loss: 0.8025 - val_accuracy: 0.6935\n",
            "Epoch 2/5\n",
            "406/406 [==============================] - 229s 564ms/step - loss: 0.6898 - accuracy: 0.7590 - val_loss: 0.6444 - val_accuracy: 0.7650\n",
            "Epoch 3/5\n",
            "406/406 [==============================] - 230s 566ms/step - loss: 0.5338 - accuracy: 0.8241 - val_loss: 0.6448 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "406/406 [==============================] - 223s 550ms/step - loss: 0.4378 - accuracy: 0.8583 - val_loss: 0.6444 - val_accuracy: 0.7688\n",
            "Epoch 5/5\n",
            "406/406 [==============================] - 223s 549ms/step - loss: 0.3599 - accuracy: 0.8876 - val_loss: 0.7132 - val_accuracy: 0.7567\n"
          ]
        }
      ],
      "source": [
        "BILSTMModelResults = BILSTMModel_2.fit(x_train, y_train, epochs=5, batch_size=64,validation_split=0.1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}